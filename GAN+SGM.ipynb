{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AhmadianGAN+StackingDriverIdentification(Final).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "avvt20LY5_Nl",
        "OPKy4l0hMW-O",
        "Iij6_ZLG5J7T",
        "n2SyHwqgMQ0T",
        "WooUgh3O5aLb",
        "sy7rpSle5hee",
        "pepLmulQ5rd7",
        "_9WJmfUT5s38",
        "lvPrIETi6oHM",
        "B2UKvzVPNy4b"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Clone Repository & Install Packages, just for google colab"
      ],
      "metadata": {
        "id": "avvt20LY5_Nl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone"
      ],
      "metadata": {
        "id": "OPKy4l0hMW-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Ruhallah93/Driver-Identification.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1pDpfLO6AQ5",
        "outputId": "e095a581-afa1-4430-fadc-b856105e8b6f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Driver-Identification' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iij6_ZLG5J7T"
      },
      "source": [
        "## Prepare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivlyit3bAo12",
        "outputId": "e2da8e0e-55c1-4b36-90ae-b0087402ed33"
      },
      "source": [
        "!pip install tsfel"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tsfel in /usr/local/lib/python3.7/dist-packages (0.1.4)\n",
            "Requirement already satisfied: ipython>=7.4.0 in /usr/local/lib/python3.7/dist-packages (from tsfel) (7.32.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from tsfel) (1.21.5)\n",
            "Requirement already satisfied: pandas>=0.25.3 in /usr/local/lib/python3.7/dist-packages (from tsfel) (1.3.5)\n",
            "Requirement already satisfied: setuptools>=47.1.1 in /usr/local/lib/python3.7/dist-packages (from tsfel) (57.4.0)\n",
            "Requirement already satisfied: oauth2client>=4.1.3 in /usr/local/lib/python3.7/dist-packages (from tsfel) (4.1.3)\n",
            "Requirement already satisfied: Sphinx>=1.8.5 in /usr/local/lib/python3.7/dist-packages (from tsfel) (1.8.6)\n",
            "Requirement already satisfied: scipy>=1.5.1 in /usr/local/lib/python3.7/dist-packages (from tsfel) (1.7.3)\n",
            "Requirement already satisfied: gspread>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tsfel) (3.4.2)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.7/dist-packages (from gspread>=3.1.0->tsfel) (1.35.0)\n",
            "Requirement already satisfied: requests>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from gspread>=3.1.0->tsfel) (2.23.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=7.4.0->tsfel) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.7/dist-packages (from ipython>=7.4.0->tsfel) (0.1.3)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.4.0->tsfel) (0.18.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.4.0->tsfel) (3.0.28)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=7.4.0->tsfel) (0.7.5)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.4.0->tsfel) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.4.0->tsfel) (5.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=7.4.0->tsfel) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=7.4.0->tsfel) (2.6.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython>=7.4.0->tsfel) (0.8.3)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.1.3->tsfel) (0.17.4)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.1.3->tsfel) (0.4.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.1.3->tsfel) (4.8)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.1.3->tsfel) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.1.3->tsfel) (0.2.8)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.3->tsfel) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.3->tsfel) (2018.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython>=7.4.0->tsfel) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.4.0->tsfel) (0.2.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.2.1->gspread>=3.1.0->tsfel) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.2.1->gspread>=3.1.0->tsfel) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.2.1->gspread>=3.1.0->tsfel) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.2.1->gspread>=3.1.0->tsfel) (1.24.3)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.8.5->tsfel) (1.2.4)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.8.5->tsfel) (2.11.3)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.8.5->tsfel) (2.2.0)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.8.5->tsfel) (1.3.0)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.8.5->tsfel) (2.9.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.8.5->tsfel) (0.7.12)\n",
            "Requirement already satisfied: docutils<0.18,>=0.11 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.8.5->tsfel) (0.17.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.8.5->tsfel) (21.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.3->Sphinx>=1.8.5->tsfel) (2.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth->gspread>=3.1.0->tsfel) (4.2.4)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->Sphinx>=1.8.5->tsfel) (3.0.7)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->Sphinx>=1.8.5->tsfel) (1.1.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxzfPYtdaRJ4",
        "outputId": "00cce687-6796-4bbb-ce0a-71dc7ee889c5"
      },
      "source": [
        "!pip install skfeature-chappers"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: skfeature-chappers in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from skfeature-chappers) (1.21.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from skfeature-chappers) (1.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from skfeature-chappers) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->skfeature-chappers) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->skfeature-chappers) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->skfeature-chappers) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->skfeature-chappers) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->skfeature-chappers) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->skfeature-chappers) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04CE-17ZnILV",
        "outputId": "50a66340-6c95-4d26-b494-edf5400d4cb0"
      },
      "source": [
        "!pip install data-complexity"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: data-complexity in /usr/local/lib/python3.7/dist-packages (0.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from data-complexity) (1.21.5)\n",
            "Requirement already satisfied: gower in /usr/local/lib/python3.7/dist-packages (from data-complexity) (0.0.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gower->data-complexity) (1.7.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2XbtQNew_si",
        "outputId": "e1ed9faa-a3ca-4a4c-beaf-1de002d82f0e"
      },
      "source": [
        "!pip install pingouin"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pingouin in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Requirement already satisfied: seaborn>=0.11 in /usr/local/lib/python3.7/dist-packages (from pingouin) (0.11.2)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.7/dist-packages (from pingouin) (1.21.5)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.7/dist-packages (from pingouin) (1.3.5)\n",
            "Requirement already satisfied: statsmodels>=0.13 in /usr/local/lib/python3.7/dist-packages (from pingouin) (0.13.2)\n",
            "Requirement already satisfied: outdated in /usr/local/lib/python3.7/dist-packages (from pingouin) (0.2.1)\n",
            "Requirement already satisfied: pandas-flavor>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pingouin) (0.2.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from pingouin) (0.8.9)\n",
            "Requirement already satisfied: matplotlib>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from pingouin) (3.2.2)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.7/dist-packages (from pingouin) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pingouin) (1.0.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->pingouin) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->pingouin) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->pingouin) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->pingouin) (1.3.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->pingouin) (2018.9)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.7/dist-packages (from pandas-flavor>=0.2.0->pingouin) (0.18.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.0.2->pingouin) (1.15.0)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.13->pingouin) (0.5.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.13->pingouin) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from outdated->pingouin) (2.23.0)\n",
            "Requirement already satisfied: littleutils in /usr/local/lib/python3.7/dist-packages (from outdated->pingouin) (0.2.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->outdated->pingouin) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->outdated->pingouin) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->outdated->pingouin) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->outdated->pingouin) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pingouin) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pingouin) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=40.4 in /usr/local/lib/python3.7/dist-packages (from xarray->pandas-flavor>=0.2.0->pingouin) (57.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "n2SyHwqgMQ0T"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8cOU0IH5MGG"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import pywt\n",
        "import tsfel\n",
        "%matplotlib inline\n",
        "import os\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from sklearn import preprocessing\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.metrics import mutual_info_score\n",
        "from skfeature.function.similarity_based import fisher_score\n",
        "from dcm import dcm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from scipy.sparse.csgraph import minimum_spanning_tree\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from scipy.spatial import distance\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WooUgh3O5aLb"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "import math\n",
        "from sklearn import preprocessing\n",
        "import seaborn as sns\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "class Utils:\n",
        "\n",
        "    def __init__(self, sample_rate):\n",
        "        self.all_features = ['x-accelerometer', 'y-accelerometer', 'z-accelerometer',\n",
        "                             'GRAVITY X (m/s²)', 'GRAVITY Y (m/s²)', 'GRAVITY Z (m/s²)',\n",
        "                             'LINEAR ACCELERATION X (m/s²)', 'LINEAR ACCELERATION Y (m/s²)',\n",
        "                             'LINEAR ACCELERATION Z (m/s²)',\n",
        "                             'x-gyroscope', 'y-gyroscope', 'z-gyroscope',\n",
        "                             'LIGHT (lux)',\n",
        "                             'MAGNETIC FIELD X (μT)', 'MAGNETIC FIELD Y (μT)', 'MAGNETIC FIELD Z (μT)',\n",
        "                             'ORIENTATION Z (azimuth °)', 'ORIENTATION X (pitch °)', 'ORIENTATION Y (roll °)',\n",
        "                             'LOCATION Latitude : ',\n",
        "                             'LOCATION Longitude : ',\n",
        "                             'LOCATION Altitude ( m)',\n",
        "                             'LOCATION Altitude-google ( m)',\n",
        "                             'LOCATION Speed ( Kmh)',\n",
        "                             'LOCATION Accuracy ( m)',\n",
        "                             'LOCATION ORIENTATION (°)',\n",
        "                             'Satellites in range',\n",
        "                             'Time since start in ms',\n",
        "                             'timestamp']\n",
        "        self.show_toolbar = True\n",
        "        self.sample_rate = sample_rate\n",
        "        self.data_split_ratio = 0.7\n",
        "\n",
        "    def read_data(self, db_path_prefix, file_name, features, driver_i):\n",
        "        db_path = db_path_prefix + file_name\n",
        "        db_new_path = db_path_prefix + \"cleaned_by_acc/\"\n",
        "\n",
        "        if os.path.exists(db_new_path + file_name):\n",
        "            data = pd.read_csv(db_new_path + file_name, low_memory=False)\n",
        "            original_size = pd.read_csv(db_path, low_memory=False).shape[0]\n",
        "            driving_size = data.shape[0]\n",
        "            stay_size = original_size - driving_size\n",
        "        else:\n",
        "            data = pd.read_csv(db_path, low_memory=False)\n",
        "            data.columns = self.all_features\n",
        "\n",
        "            original_size = data.shape[0]\n",
        "\n",
        "            def aggregate(point1, point2):\n",
        "                return math.sqrt(math.pow(point1[0] - point2[0], 2) +\n",
        "                                 math.pow(point1[1] - point2[1], 2) +\n",
        "                                 math.pow(point1[2] - point2[2], 2))\n",
        "\n",
        "            staypoints = [0]\n",
        "            points_acc = list(zip(data['x-accelerometer'], data['y-accelerometer'], data['z-accelerometer']))\n",
        "            for j in range(0, len(points_acc) - 12):\n",
        "                node = points_acc[j]\n",
        "                add = True\n",
        "                for j2 in range(j + 1, j + 12):\n",
        "                    if aggregate(node, points_acc[j2]) > 0.5:\n",
        "                        add = False\n",
        "                if add:\n",
        "                    staypoints.append(j)\n",
        "\n",
        "            if not staypoints.__contains__(len(points_acc) - 1):\n",
        "                staypoints.append(len(points_acc) - 1)\n",
        "\n",
        "            stay_size = len(staypoints)\n",
        "\n",
        "            data = data.drop(index=data['x-accelerometer'][staypoints].index)\n",
        "\n",
        "            driving_size = data.shape[0]\n",
        "\n",
        "            if not os.path.exists(db_new_path):\n",
        "                os.makedirs(db_new_path)\n",
        "            data.to_csv(db_new_path + file_name, index=False)\n",
        "\n",
        "        data = data[features]\n",
        "\n",
        "        # data = data.fillna(data.mean())\n",
        "        data = data.dropna()\n",
        "\n",
        "        clean_driving_size = data.shape[0]\n",
        "\n",
        "        template = \"{0:20}{1:20}{2:20}{3:20}{4:20}\"\n",
        "        if self.show_toolbar:\n",
        "            self.show_toolbar = False\n",
        "            print(template.format(\"driver_id: \", \"original_size: \", \"stay_size: \", \"driving_size: \",\n",
        "                                  \"cleaned_driving_size: \"))\n",
        "        print(template.format(str(driver_i),\n",
        "                              str(timedelta(seconds=int(original_size / self.sample_rate))),\n",
        "                              str(timedelta(seconds=int(stay_size / self.sample_rate))),\n",
        "                              str(timedelta(seconds=int(driving_size / self.sample_rate))),\n",
        "                              str(timedelta(seconds=int(clean_driving_size / self.sample_rate)))))\n",
        "\n",
        "        return self.split_to_train_test(data)\n",
        "\n",
        "    def split_to_train_test(self, data):\n",
        "        return data[:int(len(data) * self.data_split_ratio)], data[int(len(data) * self.data_split_ratio):]\n",
        "\n",
        "    def save_result(self, saving_path, result, data, running_time):\n",
        "        if not os.path.exists(saving_path):\n",
        "            os.makedirs(saving_path)\n",
        "        \n",
        "        # Save to file\n",
        "        with open(saving_path + 'statistics.txt', 'a') as f:\n",
        "            f.write('\\n==========***==========\\n' +\n",
        "                    datetime.now().strftime(\"%Y:%m:%d %H:%M:%S\") +\n",
        "                    '\\n' +\n",
        "                    'running time :' + str(running_time.seconds) + \" seconds\" +\n",
        "                    '\\n')\n",
        "            f.write(str(data))\n",
        "            f.write('\\n')\n",
        "            f.write(str(result))\n",
        "            f.write('\\n')"
      ],
      "metadata": {
        "id": "rvMPM2eYQfNY"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sy7rpSle5hee"
      },
      "source": [
        "# Segmentation & Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2Y3wH9y5jWV"
      },
      "source": [
        "class TransferToHistogram:\n",
        "\n",
        "    def __init__(self, window_size=90, window_ovrlap_size=45, num_bins=100):\n",
        "        self.window_size = window_size\n",
        "        self.overlapping = window_ovrlap_size\n",
        "        self.num_bins = num_bins\n",
        "\n",
        "    def transfer(self, dataset, features):\n",
        "        print(\"segmenting data with \" + str(len(dataset)) + \" points\")\n",
        "        segments, labels = self.segment_signal(dataset, features)\n",
        "        new_dataset = []\n",
        "        print(\"making \" + str(len(segments)) + \" segments\")\n",
        "        win = 0\n",
        "        for segment, label in zip(segments, labels):\n",
        "            row = []\n",
        "            win += 1\n",
        "            for feature_i in range(len(segment[1])):\n",
        "                segment_f = segment[0:, [feature_i]]\n",
        "                mu = np.mean(dataset[features[feature_i]])\n",
        "                sigma = np.std(dataset[features[feature_i]])\n",
        "                r = (mu - sigma * 2, mu + sigma * 2)\n",
        "                count, bins = np.histogram(segment_f, bins=self.num_bins, range=r)\n",
        "                his = count\n",
        "                row = np.append(row, his, axis=0)\n",
        "            row = np.append(row, [label], axis=0)\n",
        "            new_dataset.append(row)\n",
        "\n",
        "        columns = []\n",
        "        for feature in features:\n",
        "            for i in range(self.num_bins):\n",
        "                columns.append(feature + '-0_Histogram_' + str(i))\n",
        "        columns.append('id')\n",
        "        df = pd.DataFrame(new_dataset, columns=columns)\n",
        "        return df\n",
        "\n",
        "    def windows(self, data):\n",
        "        start = 0\n",
        "        while start < data.count():\n",
        "            yield int(start), int(start + self.window_size)\n",
        "            start += (self.window_size - self.overlapping)\n",
        "\n",
        "    def segment_signal(self, dataset, features):\n",
        "        segments = np.empty((0, self.window_size, len(features)))\n",
        "        labels = np.empty((0))\n",
        "        for class_i in np.unique(dataset[\"id\"]):\n",
        "            subset = dataset[dataset[\"id\"] == class_i]\n",
        "            subset = subset.reset_index(drop=True)\n",
        "            for (start, end) in self.windows(subset[\"id\"]):\n",
        "                feature_slices = []\n",
        "                for feature in features:\n",
        "                    feature_slices.append(subset[feature][start:end])\n",
        "                if len(feature_slices[0]) == self.window_size:\n",
        "                    segments = np.vstack([segments, np.dstack(\n",
        "                        [feature_slices[k] for k in range(len(feature_slices))])])\n",
        "                    labels = np.append(labels, stats.mode(subset[\"id\"][start:end])[0][0])\n",
        "        return segments, labels"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5ts63RJ5lad"
      },
      "source": [
        "import os\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import tsfel\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class TsfelFeatureExtractor:\n",
        "\n",
        "    def __init__(self, window_size=90, window_ovrlap_size=45, num_bins=100, sampling=2, approach='all'):\n",
        "        self.window_size = window_size\n",
        "        self.overlapping = window_ovrlap_size\n",
        "        self.num_bins = num_bins\n",
        "        self.sampling = sampling\n",
        "        self.approach = approach\n",
        "\n",
        "        if self.approach != 'all':\n",
        "            self.cfg = tsfel.get_features_by_domain(domain=self.approach)\n",
        "        else:\n",
        "            self.cfg = tsfel.get_features_by_domain()\n",
        "\n",
        "        # # @title Feature Extraction\n",
        "        # googleSheet_name = \"/home/ruhiii/PycharmProjects/DriverIdentification/identification/Features_Tsfel.xlsx\"\n",
        "        # # Extract excel info\n",
        "        # self.cfg = tsfel.extract_sheet(googleSheet_name)\n",
        "        # self.cfg = {'statistical': {\n",
        "        #     'Histogram': {'complexity': 'constant', 'description': 'Computes histogram of the signal.',\n",
        "        #                   'parameters': {'nbins': 10, 'r': 1}, 'function': 'tsfel.hist', 'use': 'yes'}}}\n",
        "        if self.approach == 'statistical' or self.approach == 'all':\n",
        "            self.cfg['statistical']['Histogram']['parameters']['nbins'] = self.num_bins\n",
        "\n",
        "    def transfer(self, dataset, features, using_2std=True):\n",
        "        print(\"segmenting data with \" + str(len(dataset)) + \" rows\")\n",
        "        segments, labels = self.segment_signal(dataset, features)\n",
        "        new_dataset = []\n",
        "        print(\"making \" + str(len(segments)) + \" segments\")\n",
        "        win = 0\n",
        "        for segment, label in zip(segments, labels):\n",
        "            row = []\n",
        "            win += 1\n",
        "            for feature_i in range(len(segment[1])):\n",
        "                segment_f = segment[0:, [feature_i]]\n",
        "\n",
        "                mu = np.mean(dataset[features[feature_i]])\n",
        "                sigma = np.std(dataset[features[feature_i]])\n",
        "                if using_2std:\n",
        "                    r = mu + sigma * 2\n",
        "                else:\n",
        "                    r = dataset[features[feature_i]].max()\n",
        "                if self.approach == 'statistical':\n",
        "                    self.cfg['statistical']['Histogram']['parameters']['r'] = r\n",
        "                extracted = tsfel.time_series_features_extractor(self.cfg, segment_f.reshape(1, -1)[0],\n",
        "                                                                 fs=self.sampling, verbose=0)\n",
        "                row = np.append(row, extracted.iloc[0, :], axis=0)\n",
        "\n",
        "            row = np.append(row, [label], axis=0)\n",
        "            new_dataset.append(row)\n",
        "\n",
        "        columns = []\n",
        "        for feature in features:\n",
        "            for i in extracted:\n",
        "                columns.append(feature + '-' + i)\n",
        "        columns.append('id')\n",
        "        df = pd.DataFrame(new_dataset, columns=columns)\n",
        "        return df\n",
        "\n",
        "    def feature_normalize(self, feature):\n",
        "        mu = np.mean(feature, axis=0)\n",
        "        sigma = np.std(feature, axis=0)\n",
        "        return (feature - mu) / sigma\n",
        "\n",
        "    def windows(self, data):\n",
        "        start = 0\n",
        "        while start < data.count():\n",
        "            yield int(start), int(start + self.window_size)\n",
        "            start += (self.window_size - self.overlapping)\n",
        "\n",
        "    def segment_signal(self, dataset, features):\n",
        "        segments = np.empty((0, self.window_size, len(features)))\n",
        "        labels = np.empty((0))\n",
        "        for class_i in np.unique(dataset[\"id\"]):\n",
        "            subset = dataset[dataset[\"id\"] == class_i]\n",
        "            for (start, end) in self.windows(subset[\"id\"]):\n",
        "                feature_slices = []\n",
        "                for feature in features:\n",
        "                    feature_slices.append(subset[feature][start:end])\n",
        "                if len(feature_slices[0]) == self.window_size:\n",
        "                    segments = np.vstack([segments, np.dstack(\n",
        "                        [feature_slices[k] for k in range(len(feature_slices))])])\n",
        "                    labels = np.append(labels, stats.mode(subset[\"id\"][start:end])[0][0])\n",
        "        return segments, labels\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pepLmulQ5rd7"
      },
      "source": [
        "# Augmenter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rP6uYnpf5ry1"
      },
      "source": [
        "import pywt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import model_from_json\n",
        "\n",
        "\n",
        "class Augmenter():\n",
        "    def __init__(self, filepath, input_labels):\n",
        "        self.input_labels = input_labels\n",
        "        self.latent_dim = 100\n",
        "\n",
        "        # load json and create model\n",
        "        json_file = open(filepath + '.json', 'r')\n",
        "        loaded_model_json = json_file.read()\n",
        "        json_file.close()\n",
        "        self.generator = model_from_json(loaded_model_json)\n",
        "        # load weights into new model\n",
        "        self.generator.load_weights(filepath + '.h5')\n",
        "        print(\"Loaded model from disk\")\n",
        "\n",
        "    def generate(self, num_per_driver, features):\n",
        "        generateds = self.generate_images(num_per_driver)\n",
        "\n",
        "        Gdata = generateds[0].reshape(generateds[0].shape[0], generateds[0].shape[1], generateds[0].shape[2])\n",
        "        X_generated = []\n",
        "        # each generate windows\n",
        "        for i in range(Gdata.shape[0]):\n",
        "            cell = []\n",
        "            # each axis\n",
        "            for j in range(0, Gdata.shape[1], 2):\n",
        "                cell.append(pywt.idwt(Gdata[i, j, :], Gdata[i, j + 1, :], 'db2', 'smooth').tolist())\n",
        "            X_generated.append(cell)\n",
        "\n",
        "        print(np.shape(X_generated))\n",
        "        X_generated1 = np.array(X_generated)\n",
        "        X_generated2 = X_generated1.swapaxes(1, 2)\n",
        "        X_generated3 = X_generated2.reshape(X_generated2.shape[0] * X_generated2.shape[1], X_generated2.shape[2])\n",
        "        y_generated = generateds[1].repeat(X_generated2.shape[1])\n",
        "        Data_generated = pd.DataFrame(X_generated3, columns=features)\n",
        "        Data_generated['id'] = y_generated.tolist()\n",
        "        Data_generated['id'] = Data_generated['id'] + 201\n",
        "        return Data_generated\n",
        "\n",
        "    def generate_images(self, num):\n",
        "        labels = np.array(self.input_labels)\n",
        "        sampled_labels = labels.reshape(-1, 1)\n",
        "        for i in range(num):\n",
        "            noise = np.random.normal(0, 1, (len(labels), self.latent_dim))\n",
        "            if i == 0:\n",
        "                sampled_images = self.generator.predict([noise, sampled_labels])\n",
        "                final_labels = labels\n",
        "            else:\n",
        "                sampled_images = np.concatenate((sampled_images, self.generator.predict([noise, sampled_labels])),\n",
        "                                                axis=0)\n",
        "                final_labels = np.concatenate((final_labels, labels), axis=0)\n",
        "        return (sampled_images, final_labels)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9WJmfUT5s38"
      },
      "source": [
        "# VARIABLES"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def initialization(n_driver):\n",
        "  global features\n",
        "  features = ['x-accelerometer','y-accelerometer','z-accelerometer','x-gyroscope','y-gyroscope','z-gyroscope']\n",
        "  global db_path_prefix\n",
        "  db_path_prefix = 'Driver-Identification/dataset/'\n",
        "  global sample_rate\n",
        "  sample_rate = 2\n",
        "\n",
        "  global window_size\n",
        "  window_size = sample_rate * 60 * 15\n",
        "  global overlapping\n",
        "  overlapping = int(window_size * 0.75)\n",
        "\n",
        "  global utils\n",
        "  utils = Utils(sample_rate=sample_rate)"
      ],
      "metadata": {
        "id": "s8wEia_GQU1r"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFJpjq5t5wj4"
      },
      "source": [
        "#SEGMENTATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JClJf7oe5yFG"
      },
      "source": [
        "def read_data(drivers):\n",
        "  global train_dataset\n",
        "  train_dataset = pd.DataFrame()\n",
        "  global test_dataset\n",
        "  test_dataset = pd.DataFrame()\n",
        "  global labels\n",
        "  labels = []\n",
        "  for i in drivers:\n",
        "    labels.append(i-201)\n",
        "    train_temp_dataset, test_temp_dataset = utils.read_data(db_path_prefix, str(i) + '.1.csv', features, i)\n",
        "    train_temp_dataset['id'] = i\n",
        "    test_temp_dataset['id'] = i\n",
        "    train_dataset = pd.concat([train_dataset, train_temp_dataset])\n",
        "    test_dataset = pd.concat([test_dataset, test_temp_dataset])"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-8QBF4C5zoK"
      },
      "source": [
        "def Standardization(X_train, X_test):\n",
        "  CX_train = X_train.copy()\n",
        "  CX_test = X_test.copy()\n",
        "\n",
        "  C = pd.concat([CX_train, CX_test])\n",
        "  NC = preprocessing.scale(C)\n",
        "  NCX_train = NC[: len(CX_train)]\n",
        "  NCX_test = NC[len(CX_train):]\n",
        "\n",
        "  return NCX_train, NCX_test"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABADezy_50xS"
      },
      "source": [
        "def data_standardization():\n",
        "  global n_train_dataset\n",
        "  global n_test_dataset\n",
        "  n_train_dataset, n_test_dataset = Standardization(train_dataset.iloc[:, :-1], test_dataset.iloc[:, :-1])\n",
        "  n_train_dataset = pd.DataFrame(n_train_dataset, columns=features)\n",
        "  n_test_dataset = pd.DataFrame(n_test_dataset, columns=features)\n",
        "  n_train_dataset['id'] = train_dataset.iloc[:, -1].tolist()\n",
        "  n_test_dataset['id'] = test_dataset.iloc[:, -1].tolist()"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNk3FgT151xg"
      },
      "source": [
        "def data_augmentation(b:bool):\n",
        "  global an_train_dataset\n",
        "  if b:\n",
        "    augment_size_per_driver = 6 * 15\n",
        "    generator = Augmenter(\"Driver-Identification/model/GAN-g-(4)20\", labels)\n",
        "    generated = generator.generate(augment_size_per_driver, features)\n",
        "    n_generated = preprocessing.scale(generated.iloc[:, :-1])\n",
        "    n_generated = pd.DataFrame(n_generated, columns=features)\n",
        "    n_generated['id'] = generated.iloc[:, -1].tolist()\n",
        "    an_train_dataset = pd.concat([n_train_dataset, n_generated])\n",
        "  else:\n",
        "    an_train_dataset = n_train_dataset"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCGiB_WS53VD"
      },
      "source": [
        "def feature_extraction(approach):\n",
        "    global S_train\n",
        "    global S_test\n",
        "    if approach == 'histogram':\n",
        "      featureExtractor = TransferToHistogram(window_size=window_size, \n",
        "                                             window_ovrlap_size=overlapping, \n",
        "                                             num_bins=100)\n",
        "    else:\n",
        "      featureExtractor = TsfelFeatureExtractor(window_size=window_size,\n",
        "                                               window_ovrlap_size=overlapping,\n",
        "                                               num_bins=100,\n",
        "                                               approach=approach)\n",
        "    \n",
        "    S_train = featureExtractor.transfer(an_train_dataset, features)\n",
        "    S_test = featureExtractor.transfer(n_test_dataset, features)\n",
        "\n",
        "    global SX_train\n",
        "    SX_train = S_train.iloc[:, :-1]\n",
        "    global y_train\n",
        "    y_train = S_train.iloc[:, -1]\n",
        "    global SX_test\n",
        "    SX_test = S_test.iloc[:, :-1]\n",
        "    global y_test\n",
        "    y_test = S_test.iloc[:, -1]\n",
        "\n",
        "    replace_y_numbers = {k: v for v, k in enumerate(sorted(set(y_train)))}\n",
        "    y_train = y_train.replace(replace_y_numbers)\n",
        "    y_test = y_test.replace(replace_y_numbers)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEN_ZnhK54r3"
      },
      "source": [
        "def correlation_report(features, threshold=0.95):\n",
        "    features = pd.DataFrame(features)\n",
        "    corr_matrix = features.corr()\n",
        "\n",
        "    # Select upper triangle of correlation matrix\n",
        "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
        "    # Find index and column name of features with correlation greater than 0.95\n",
        "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
        "    # if len(to_drop) == 0:\n",
        "    #     print('No features to remove')\n",
        "    # for rej in to_drop:\n",
        "    #     print('Removing ' + str(rej))\n",
        "\n",
        "    return to_drop"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WuuXP8B56aX"
      },
      "source": [
        "def feature_selection():\n",
        "  to_drop = correlation_report(SX_train.copy(), threshold=0.95)\n",
        "  global SSX_train, SSX_test\n",
        "  SSX_train = SX_train.drop(to_drop, axis=1)\n",
        "  SSX_test = SX_test.drop(to_drop, axis=1)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QZY7vwq57gY"
      },
      "source": [
        "def Normalization(X_train, X_test):\n",
        "  CX_train = X_train.copy()\n",
        "  CX_test = X_test.copy()\n",
        "\n",
        "  scaler = preprocessing.Normalizer()\n",
        "  scaler = scaler.fit(CX_train)\n",
        "  NCX_train = scaler.transform(CX_train)\n",
        "  NCX_test = scaler.transform(CX_test)\n",
        "  \n",
        "  return NCX_train, NCX_test"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GY5n9VbQ58nF"
      },
      "source": [
        "def feature_normalization():\n",
        "  global NSX_train\n",
        "  global NSX_test\n",
        "  NSX_train, NSX_test = Normalization(SSX_train, SSX_test)\n",
        "  NSX_train = pd.DataFrame(NSX_train)\n",
        "  NSX_test = pd.DataFrame(NSX_test)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvPrIETi6oHM"
      },
      "source": [
        "# TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iEokCh86pMt"
      },
      "source": [
        "def train_model():\n",
        "  svc = LinearSVC()\n",
        "  mlp = MLPClassifier()\n",
        "  knn = KNeighborsClassifier()\n",
        "  rf4 = RandomForestClassifier(n_jobs=70, bootstrap=False, max_depth=2000, max_features=0.01, n_estimators=1500)\n",
        "  mlp3 = MLPClassifier(hidden_layer_sizes=600, max_iter=1000, random_state=1, solver='adam', alpha=0.01, momentum=0.9)\n",
        "  algms = [('svc', svc), ('mlp', mlp), ('knn', knn), ('rf1', rf4)]\n",
        "  model = StackingClassifier(estimators=algms, final_estimator=LogisticRegression())\n",
        "  model_train = model.fit(NSX_train, y_train)\n",
        "  tmp = model.predict(NSX_test)\n",
        "  accuracy = accuracy_score(y_test, tmp)\n",
        "  precision = precision_score(y_test, tmp, average='macro')\n",
        "  recall = recall_score(y_test, tmp, average='macro')\n",
        "  f1 = f1_score(y_test, tmp, average='macro')\n",
        "  return accuracy, precision, recall, f1"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6icwCnJi6qbM"
      },
      "source": [
        "def save_result(approach, accuracy_list, recall_list, precision_list, f1_list, running_time):\n",
        "  saving_path = 'log/'\n",
        "  data = {'window size':window_size / (60*sample_rate),'overlap':overlapping / window_size, \n",
        "          'approach':approach, 'dataset':'eftekhari', 'drivers':n_driver, 'features':features}\n",
        "  (accuracy_mean,accuracy_std) = (np.average(accuracy_list),np.std(accuracy_list))\n",
        "  (recall_mean,recall_std) = (np.average(recall_list),np.std(recall_list))\n",
        "  (precision_mean,precision_std) = (np.average(precision_list),np.std(precision_list))\n",
        "  (f1_mean,f1_std) = (np.average(f1_list),np.std(f1_list))\n",
        "  result = {\n",
        "      'accuracy_mean':accuracy_mean,'accuracy_std':accuracy_std,\n",
        "      'recall_mean':recall_mean,'recall_std':recall_std,\n",
        "      'precision_mean':precision_mean,'precision_mean':precision_mean,\n",
        "      'f1_mean':f1_mean,'f1_std':f1_std,\n",
        "  }\n",
        "  print('\\nMean Accuracy:{:.4f}({:.4f}) Mean Recall:{:.4f}({:.4f}) Mean Precision:{:.4f}({:.4f}) Mean F1:{:.4f}({:.4f})\\n'.format(\n",
        "      accuracy_mean,accuracy_std, recall_mean,recall_std, precision_mean,precision_std, f1_mean,f1_std))\n",
        "  utils.save_result(saving_path=saving_path, result=result, data=data, running_time=running_time)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewqdXAYy5-Bm"
      },
      "source": [
        "# RUN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqSG4mWN5gN4",
        "outputId": "d0ba4631-9470-4f79-9628-cdaa543140b4"
      },
      "source": [
        "for n_driver in range(10,11):\n",
        "  drivers = random.sample([i for i in range(201,211)], n_driver)\n",
        "  for approach in ['histogram', 'statistical', 'all', 'temporal', 'spectral']:\n",
        "    for data_aug_condition in [True]:\n",
        "        accuracy_list = []\n",
        "        recall_list = []\n",
        "        precision_list = []\n",
        "        f1_list = []\n",
        "        start = datetime.now()\n",
        "        for i in range(10):\n",
        "          initialization(n_driver)\n",
        "          read_data(drivers)\n",
        "          data_standardization()\n",
        "          data_augmentation(data_aug_condition)\n",
        "          feature_extraction(approach)\n",
        "          feature_selection()\n",
        "          feature_normalization()\n",
        "\n",
        "          accuracy, precision, recall, f1 = train_model()\n",
        "          accuracy_list.append(accuracy)\n",
        "          precision_list.append(precision)\n",
        "          recall_list.append(recall)\n",
        "          f1_list.append(f1)\n",
        "          print('Feature Set: %s \\t Augmentation: %s' % (approach, data_aug_condition))\n",
        "          print('Accuracy:{:.4f}, Precision:{:.4f}, Recall:{:.4f}, F1:{:.4f}'.format(accuracy, precision, recall, f1))\n",
        "        end = datetime.now()\n",
        "        running_time = end - start\n",
        "        save_result(approach, accuracy_list, recall_list, precision_list, f1_list, running_time)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "driver_id:          original_size:      stay_size:          driving_size:       cleaned_driving_size: \n",
            "207                 12:13:19            9:10:35             3:02:44             3:02:39             \n",
            "208                 8:00:58             5:54:09             2:06:49             2:06:44             \n",
            "201                 4:19:09             2:38:41             1:40:28             1:40:28             \n",
            "202                 6:53:36             4:59:01             1:54:35             1:54:35             \n",
            "205                 9:38:07             8:10:24             1:27:43             1:27:38             \n",
            "204                 8:39:25             6:50:00             1:49:25             1:49:19             \n",
            "206                 6:44:40             4:46:42             1:57:58             1:57:52             \n",
            "209                 6:34:13             4:20:44             2:13:29             2:13:24             \n",
            "203                 8:24:28             5:41:16             2:43:11             2:43:06             \n",
            "210                 6:05:37             3:14:38             2:50:59             2:50:54             \n",
            "Loaded model from disk\n",
            "(900, 6, 20)\n",
            "segmenting data with 127756 points\n",
            "making 249 segments\n",
            "segmenting data with 47044 points\n",
            "making 71 segments\n",
            "Feature Set: histogram \t Augmentation: True\n",
            "Accuracy:0.9014, Precision:0.9340, Recall:0.9057, F1:0.9082\n",
            "driver_id:          original_size:      stay_size:          driving_size:       cleaned_driving_size: \n",
            "207                 12:13:19            9:10:35             3:02:44             3:02:39             \n",
            "208                 8:00:58             5:54:09             2:06:49             2:06:44             \n",
            "201                 4:19:09             2:38:41             1:40:28             1:40:28             \n",
            "202                 6:53:36             4:59:01             1:54:35             1:54:35             \n",
            "205                 9:38:07             8:10:24             1:27:43             1:27:38             \n",
            "204                 8:39:25             6:50:00             1:49:25             1:49:19             \n",
            "206                 6:44:40             4:46:42             1:57:58             1:57:52             \n",
            "209                 6:34:13             4:20:44             2:13:29             2:13:24             \n",
            "203                 8:24:28             5:41:16             2:43:11             2:43:06             \n",
            "210                 6:05:37             3:14:38             2:50:59             2:50:54             \n",
            "Loaded model from disk\n",
            "(900, 6, 20)\n",
            "segmenting data with 127756 points\n",
            "making 249 segments\n",
            "segmenting data with 47044 points\n",
            "making 71 segments\n",
            "Feature Set: histogram \t Augmentation: True\n",
            "Accuracy:0.9296, Precision:0.9485, Recall:0.9257, F1:0.9289\n",
            "driver_id:          original_size:      stay_size:          driving_size:       cleaned_driving_size: \n",
            "207                 12:13:19            9:10:35             3:02:44             3:02:39             \n",
            "208                 8:00:58             5:54:09             2:06:49             2:06:44             \n",
            "201                 4:19:09             2:38:41             1:40:28             1:40:28             \n",
            "202                 6:53:36             4:59:01             1:54:35             1:54:35             \n",
            "205                 9:38:07             8:10:24             1:27:43             1:27:38             \n",
            "204                 8:39:25             6:50:00             1:49:25             1:49:19             \n",
            "206                 6:44:40             4:46:42             1:57:58             1:57:52             \n",
            "209                 6:34:13             4:20:44             2:13:29             2:13:24             \n",
            "203                 8:24:28             5:41:16             2:43:11             2:43:06             \n",
            "210                 6:05:37             3:14:38             2:50:59             2:50:54             \n",
            "Loaded model from disk\n",
            "(900, 6, 20)\n",
            "segmenting data with 127756 points\n",
            "making 249 segments\n",
            "segmenting data with 47044 points\n",
            "making 71 segments\n",
            "Feature Set: histogram \t Augmentation: True\n",
            "Accuracy:0.9155, Precision:0.9411, Recall:0.9157, F1:0.9188\n",
            "driver_id:          original_size:      stay_size:          driving_size:       cleaned_driving_size: \n",
            "207                 12:13:19            9:10:35             3:02:44             3:02:39             \n",
            "208                 8:00:58             5:54:09             2:06:49             2:06:44             \n",
            "201                 4:19:09             2:38:41             1:40:28             1:40:28             \n",
            "202                 6:53:36             4:59:01             1:54:35             1:54:35             \n",
            "205                 9:38:07             8:10:24             1:27:43             1:27:38             \n",
            "204                 8:39:25             6:50:00             1:49:25             1:49:19             \n",
            "206                 6:44:40             4:46:42             1:57:58             1:57:52             \n",
            "209                 6:34:13             4:20:44             2:13:29             2:13:24             \n",
            "203                 8:24:28             5:41:16             2:43:11             2:43:06             \n",
            "210                 6:05:37             3:14:38             2:50:59             2:50:54             \n",
            "Loaded model from disk\n",
            "(900, 6, 20)\n",
            "segmenting data with 127756 points\n",
            "making 249 segments\n",
            "segmenting data with 47044 points\n",
            "making 71 segments\n",
            "Feature Set: histogram \t Augmentation: True\n",
            "Accuracy:0.9155, Precision:0.9411, Recall:0.9157, F1:0.9188\n",
            "driver_id:          original_size:      stay_size:          driving_size:       cleaned_driving_size: \n",
            "207                 12:13:19            9:10:35             3:02:44             3:02:39             \n",
            "208                 8:00:58             5:54:09             2:06:49             2:06:44             \n",
            "201                 4:19:09             2:38:41             1:40:28             1:40:28             \n",
            "202                 6:53:36             4:59:01             1:54:35             1:54:35             \n",
            "205                 9:38:07             8:10:24             1:27:43             1:27:38             \n",
            "204                 8:39:25             6:50:00             1:49:25             1:49:19             \n",
            "206                 6:44:40             4:46:42             1:57:58             1:57:52             \n",
            "209                 6:34:13             4:20:44             2:13:29             2:13:24             \n",
            "203                 8:24:28             5:41:16             2:43:11             2:43:06             \n",
            "210                 6:05:37             3:14:38             2:50:59             2:50:54             \n",
            "Loaded model from disk\n",
            "(900, 6, 20)\n",
            "segmenting data with 127756 points\n",
            "making 249 segments\n",
            "segmenting data with 47044 points\n",
            "making 71 segments\n",
            "Feature Set: histogram \t Augmentation: True\n",
            "Accuracy:0.9155, Precision:0.9411, Recall:0.9157, F1:0.9188\n",
            "driver_id:          original_size:      stay_size:          driving_size:       cleaned_driving_size: \n",
            "207                 12:13:19            9:10:35             3:02:44             3:02:39             \n",
            "208                 8:00:58             5:54:09             2:06:49             2:06:44             \n",
            "201                 4:19:09             2:38:41             1:40:28             1:40:28             \n",
            "202                 6:53:36             4:59:01             1:54:35             1:54:35             \n",
            "205                 9:38:07             8:10:24             1:27:43             1:27:38             \n",
            "204                 8:39:25             6:50:00             1:49:25             1:49:19             \n",
            "206                 6:44:40             4:46:42             1:57:58             1:57:52             \n",
            "209                 6:34:13             4:20:44             2:13:29             2:13:24             \n",
            "203                 8:24:28             5:41:16             2:43:11             2:43:06             \n",
            "210                 6:05:37             3:14:38             2:50:59             2:50:54             \n",
            "Loaded model from disk\n",
            "(900, 6, 20)\n",
            "segmenting data with 127756 points\n",
            "making 249 segments\n",
            "segmenting data with 47044 points\n",
            "making 71 segments\n",
            "Feature Set: histogram \t Augmentation: True\n",
            "Accuracy:0.9014, Precision:0.9340, Recall:0.9057, F1:0.9082\n",
            "driver_id:          original_size:      stay_size:          driving_size:       cleaned_driving_size: \n",
            "207                 12:13:19            9:10:35             3:02:44             3:02:39             \n",
            "208                 8:00:58             5:54:09             2:06:49             2:06:44             \n",
            "201                 4:19:09             2:38:41             1:40:28             1:40:28             \n",
            "202                 6:53:36             4:59:01             1:54:35             1:54:35             \n",
            "205                 9:38:07             8:10:24             1:27:43             1:27:38             \n",
            "204                 8:39:25             6:50:00             1:49:25             1:49:19             \n",
            "206                 6:44:40             4:46:42             1:57:58             1:57:52             \n",
            "209                 6:34:13             4:20:44             2:13:29             2:13:24             \n",
            "203                 8:24:28             5:41:16             2:43:11             2:43:06             \n",
            "210                 6:05:37             3:14:38             2:50:59             2:50:54             \n",
            "Loaded model from disk\n",
            "(900, 6, 20)\n",
            "segmenting data with 127756 points\n",
            "making 249 segments\n",
            "segmenting data with 47044 points\n",
            "making 71 segments\n",
            "Feature Set: histogram \t Augmentation: True\n",
            "Accuracy:0.9155, Precision:0.9411, Recall:0.9157, F1:0.9188\n",
            "driver_id:          original_size:      stay_size:          driving_size:       cleaned_driving_size: \n",
            "207                 12:13:19            9:10:35             3:02:44             3:02:39             \n",
            "208                 8:00:58             5:54:09             2:06:49             2:06:44             \n",
            "201                 4:19:09             2:38:41             1:40:28             1:40:28             \n",
            "202                 6:53:36             4:59:01             1:54:35             1:54:35             \n",
            "205                 9:38:07             8:10:24             1:27:43             1:27:38             \n",
            "204                 8:39:25             6:50:00             1:49:25             1:49:19             \n",
            "206                 6:44:40             4:46:42             1:57:58             1:57:52             \n",
            "209                 6:34:13             4:20:44             2:13:29             2:13:24             \n",
            "203                 8:24:28             5:41:16             2:43:11             2:43:06             \n",
            "210                 6:05:37             3:14:38             2:50:59             2:50:54             \n",
            "Loaded model from disk\n",
            "(900, 6, 20)\n",
            "segmenting data with 127756 points\n",
            "making 249 segments\n",
            "segmenting data with 47044 points\n",
            "making 71 segments\n",
            "Feature Set: histogram \t Augmentation: True\n",
            "Accuracy:0.9296, Precision:0.9485, Recall:0.9257, F1:0.9289\n",
            "driver_id:          original_size:      stay_size:          driving_size:       cleaned_driving_size: \n",
            "207                 12:13:19            9:10:35             3:02:44             3:02:39             \n",
            "208                 8:00:58             5:54:09             2:06:49             2:06:44             \n",
            "201                 4:19:09             2:38:41             1:40:28             1:40:28             \n",
            "202                 6:53:36             4:59:01             1:54:35             1:54:35             \n",
            "205                 9:38:07             8:10:24             1:27:43             1:27:38             \n",
            "204                 8:39:25             6:50:00             1:49:25             1:49:19             \n",
            "206                 6:44:40             4:46:42             1:57:58             1:57:52             \n",
            "209                 6:34:13             4:20:44             2:13:29             2:13:24             \n",
            "203                 8:24:28             5:41:16             2:43:11             2:43:06             \n",
            "210                 6:05:37             3:14:38             2:50:59             2:50:54             \n",
            "Loaded model from disk\n",
            "(900, 6, 20)\n",
            "segmenting data with 127756 points\n",
            "making 249 segments\n",
            "segmenting data with 47044 points\n",
            "making 71 segments\n",
            "Feature Set: histogram \t Augmentation: True\n",
            "Accuracy:0.9155, Precision:0.9411, Recall:0.9157, F1:0.9188\n",
            "driver_id:          original_size:      stay_size:          driving_size:       cleaned_driving_size: \n",
            "207                 12:13:19            9:10:35             3:02:44             3:02:39             \n",
            "208                 8:00:58             5:54:09             2:06:49             2:06:44             \n",
            "201                 4:19:09             2:38:41             1:40:28             1:40:28             \n",
            "202                 6:53:36             4:59:01             1:54:35             1:54:35             \n",
            "205                 9:38:07             8:10:24             1:27:43             1:27:38             \n",
            "204                 8:39:25             6:50:00             1:49:25             1:49:19             \n",
            "206                 6:44:40             4:46:42             1:57:58             1:57:52             \n",
            "209                 6:34:13             4:20:44             2:13:29             2:13:24             \n",
            "203                 8:24:28             5:41:16             2:43:11             2:43:06             \n",
            "210                 6:05:37             3:14:38             2:50:59             2:50:54             \n",
            "Loaded model from disk\n",
            "(900, 6, 20)\n",
            "segmenting data with 127756 points\n",
            "making 249 segments\n",
            "segmenting data with 47044 points\n",
            "making 71 segments\n",
            "Feature Set: histogram \t Augmentation: True\n",
            "Accuracy:0.9014, Precision:0.9340, Recall:0.9057, F1:0.9082\n",
            "\n",
            "Mean Accuracy:0.9141(0.0099) Mean Recall:0.9147(0.0070) Mean Precision:0.9405(0.0050) Mean F1:0.9176(0.0073)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdYGvfV4v7xY"
      },
      "source": [
        "#**analysing**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MRMR"
      ],
      "metadata": {
        "id": "B2UKvzVPNy4b"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thESJEj6wjJ4"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_selection import f_regression\n",
        "\n",
        "# inputs:\n",
        "#    X: pandas.DataFrame, features\n",
        "#    y: pandas.Series, target variable\n",
        "#    K: number of features to select\n",
        "\n",
        "def _mrmr_base(X, y, K, approach):\n",
        "  # compute F-statistics and initialize correlation matrix\n",
        "  X = X.reset_index(drop=True)\n",
        "  \n",
        "  F = pd.Series(f_regression(X, y)[0], index = X.columns)\n",
        "  # rf = RandomForestClassifier(max_depth=2, random_state=0)\n",
        "  # rf.fit(X, y)\n",
        "  # F = pd.Series(rf.feature_importances_, index = X.columns)\n",
        "\n",
        "  corr = pd.DataFrame(.00001, index = X.columns, columns = X.columns)\n",
        "\n",
        "  # initialize list of selected features and list of excluded features\n",
        "  selected = []\n",
        "  scores = []\n",
        "  rels = []\n",
        "  reds = []\n",
        "  combination = []\n",
        "  not_selected = X.columns.to_list()\n",
        "\n",
        "  # repeat K times\n",
        "  for i in range(K):\n",
        "    \n",
        "      # compute (absolute) correlations between the last selected feature and all the (currently) excluded features\n",
        "      if i > 0:\n",
        "          last_selected = selected[-1]\n",
        "          corr.loc[not_selected, last_selected] = X[not_selected].corrwith(X[last_selected]).abs().clip(.00001).fillna(.00001)\n",
        "\n",
        "      # compute FCQ score for all the (currently) excluded features (this is Formula 2)\n",
        "      rel = F.loc[not_selected].fillna(.00001)\n",
        "      red = corr.loc[not_selected, selected].mean(axis = 1).round(5).fillna(.00001).replace(1.0, float('Inf'))\n",
        "      score = rel / red\n",
        "\n",
        "      # find best feature, add it to selected and remove it from not_selected\n",
        "      if len(score) > 0:\n",
        "        # print(score.argmax())\n",
        "        best = score.index[score.argmax()]\n",
        "        selected.append(best)\n",
        "        not_selected.remove(best)\n",
        "        rels.append(rel.iloc[score.argmax()])\n",
        "        reds.append(red.iloc[score.argmax()])\n",
        "        scores.append(score.max())\n",
        "        combination.append([score.max(),rel.iloc[score.argmax()],red.iloc[score.argmax()],approach])\n",
        "        # print(best, score.max())\n",
        "  return scores, rels, reds, combination, selected"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns =['scores','rels','reds','method']\n",
        "df = pd.DataFrame(columns = columns)\n",
        "for n_driver in range(10,11):\n",
        "  drivers = random.sample([i for i in range(201,211)], n_driver)\n",
        "  for approach in ['histogram']:\n",
        "    for data_aug_condition in [True, False]:\n",
        "        initialization(n_driver)\n",
        "        read_data(drivers)\n",
        "        data_standardization()\n",
        "        data_augmentation(data_aug_condition)\n",
        "        feature_extraction(approach)\n",
        "        # feature_selection()\n",
        "        # feature_normalization()\n",
        "        Xsubset = SX_train\n",
        "        Ysubset = y_train\n",
        "        \n",
        "        method = approach + \" \" + str(data_aug_condition)\n",
        "        scores, rels, reds, combination, selected = _mrmr_base(Xsubset, Ysubset, Xsubset.shape[1], method)\n",
        "        df = pd.concat([df, pd.DataFrame(combination, columns = columns)])\n",
        "\n",
        "        print(approach, data_aug_condition, Xsubset.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMEHVwYnrrW8",
        "outputId": "cd599c17-d4f6-40c3-9704-2a3b8a7b0473"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "driver_id:          original_size:      stay_size:          driving_size:       cleaned_driving_size: \n",
            "202                 6:53:36             4:59:01             1:54:35             1:54:35             \n",
            "204                 8:39:25             6:50:00             1:49:25             1:49:19             \n",
            "209                 6:34:13             4:20:44             2:13:29             2:13:24             \n",
            "206                 6:44:40             4:46:42             1:57:58             1:57:52             \n",
            "208                 8:00:58             5:54:09             2:06:49             2:06:44             \n",
            "205                 9:38:07             8:10:24             1:27:43             1:27:38             \n",
            "203                 8:24:28             5:41:16             2:43:11             2:43:06             \n",
            "201                 4:19:09             2:38:41             1:40:28             1:40:28             \n",
            "207                 12:13:19            9:10:35             3:02:44             3:02:39             \n",
            "210                 6:05:37             3:14:38             2:50:59             2:50:54             \n",
            "Loaded model from disk\n",
            "(900, 6, 20)\n",
            "segmenting data with 127756 points\n",
            "making 249 segments\n",
            "segmenting data with 47044 points\n",
            "making 71 segments\n",
            "histogram True (249, 600)\n",
            "driver_id:          original_size:      stay_size:          driving_size:       cleaned_driving_size: \n",
            "202                 6:53:36             4:59:01             1:54:35             1:54:35             \n",
            "204                 8:39:25             6:50:00             1:49:25             1:49:19             \n",
            "209                 6:34:13             4:20:44             2:13:29             2:13:24             \n",
            "206                 6:44:40             4:46:42             1:57:58             1:57:52             \n",
            "208                 8:00:58             5:54:09             2:06:49             2:06:44             \n",
            "205                 9:38:07             8:10:24             1:27:43             1:27:38             \n",
            "203                 8:24:28             5:41:16             2:43:11             2:43:06             \n",
            "201                 4:19:09             2:38:41             1:40:28             1:40:28             \n",
            "207                 12:13:19            9:10:35             3:02:44             3:02:39             \n",
            "210                 6:05:37             3:14:38             2:50:59             2:50:54             \n",
            "segmenting data with 109756 points\n",
            "making 209 segments\n",
            "segmenting data with 47044 points\n",
            "making 71 segments\n",
            "histogram False (209, 600)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrLorYkM0y33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "6043b948-ec04-4495-fec6-230311c290ec"
      },
      "source": [
        "df.groupby(\"method\").mean()"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f9f99be9-5294-427e-a398-f0d9da1f422f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>scores</th>\n",
              "      <th>rels</th>\n",
              "      <th>reds</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>method</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>histogram False</th>\n",
              "      <td>14016.789598</td>\n",
              "      <td>13.721216</td>\n",
              "      <td>0.227846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>histogram True</th>\n",
              "      <td>14694.131199</td>\n",
              "      <td>13.967997</td>\n",
              "      <td>0.217602</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9f99be9-5294-427e-a398-f0d9da1f422f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f9f99be9-5294-427e-a398-f0d9da1f422f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f9f99be9-5294-427e-a398-f0d9da1f422f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                       scores       rels      reds\n",
              "method                                            \n",
              "histogram False  14016.789598  13.721216  0.227846\n",
              "histogram True   14694.131199  13.967997  0.217602"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuAfrQ2BVewD"
      },
      "source": [
        "## Random Forest "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns =['scores', 'method']\n",
        "df = pd.DataFrame(columns = columns)\n",
        "for n_driver in range(10,11):\n",
        "  drivers = random.sample([i for i in range(201,211)], n_driver)\n",
        "  for approach in ['all', 'histogram', 'statistical', 'temporal', 'spectral']:\n",
        "    for data_aug_condition in [True]:\n",
        "        initialization(n_driver)\n",
        "        read_data(drivers)\n",
        "        data_standardization()\n",
        "        data_augmentation(data_aug_condition)\n",
        "        feature_extraction('all')\n",
        "        Xset = SX_train\n",
        "        Yset = y_train\n",
        "\n",
        "        initialization(n_driver)\n",
        "        read_data(drivers)\n",
        "        data_standardization()\n",
        "        data_augmentation(data_aug_condition)\n",
        "        feature_extraction(approach)\n",
        "        feature_selection()\n",
        "        Xsubset = SSX_train\n",
        "        \n",
        "        rf = RandomForestClassifier(max_depth=2, random_state=0)\n",
        "        rf.fit(Xset, Yset)\n",
        "\n",
        "        sam = pd.DataFrame()\n",
        "        sam['score'] = rf.feature_importances_\n",
        "        sam.index = Xset.columns.to_list()\n",
        "        score = []\n",
        "        for label in Xsubset.columns.to_list():\n",
        "            score.append([sam.loc[label].score, approach])\n",
        "        df = pd.concat([df, pd.DataFrame(score, columns = columns)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3El9SYdONIo",
        "outputId": "872e7bdc-f509-43fb-bbb2-fc0aa1956ba2"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "driver_id:          original_size:      stay_size:          driving_size:       cleaned_driving_size: \n",
            "206                 6:44:40             4:46:42             1:57:58             1:57:52             \n",
            "210                 6:05:37             3:14:38             2:50:59             2:50:54             \n",
            "207                 12:13:19            9:10:35             3:02:44             3:02:39             \n",
            "205                 9:38:07             8:10:24             1:27:43             1:27:38             \n",
            "209                 6:34:13             4:20:44             2:13:29             2:13:24             \n",
            "204                 8:39:25             6:50:00             1:49:25             1:49:19             \n",
            "208                 8:00:58             5:54:09             2:06:49             2:06:44             \n",
            "201                 4:19:09             2:38:41             1:40:28             1:40:28             \n",
            "203                 8:24:28             5:41:16             2:43:11             2:43:06             \n",
            "202                 6:53:36             4:59:01             1:54:35             1:54:35             \n",
            "Loaded model from disk\n",
            "(900, 6, 20)\n",
            "segmenting data with 127756 rows\n",
            "making 249 segments\n",
            "segmenting data with 47044 rows\n",
            "making 71 segments\n",
            "driver_id:          original_size:      stay_size:          driving_size:       cleaned_driving_size: \n",
            "206                 6:44:40             4:46:42             1:57:58             1:57:52             \n",
            "210                 6:05:37             3:14:38             2:50:59             2:50:54             \n",
            "207                 12:13:19            9:10:35             3:02:44             3:02:39             \n",
            "205                 9:38:07             8:10:24             1:27:43             1:27:38             \n",
            "209                 6:34:13             4:20:44             2:13:29             2:13:24             \n",
            "204                 8:39:25             6:50:00             1:49:25             1:49:19             \n",
            "208                 8:00:58             5:54:09             2:06:49             2:06:44             \n",
            "201                 4:19:09             2:38:41             1:40:28             1:40:28             \n",
            "203                 8:24:28             5:41:16             2:43:11             2:43:06             \n",
            "202                 6:53:36             4:59:01             1:54:35             1:54:35             \n",
            "Loaded model from disk\n",
            "(900, 6, 20)\n",
            "segmenting data with 127756 rows\n",
            "making 249 segments\n",
            "segmenting data with 47044 rows\n",
            "making 71 segments\n",
            "driver_id:          original_size:      stay_size:          driving_size:       cleaned_driving_size: \n",
            "206                 6:44:40             4:46:42             1:57:58             1:57:52             \n",
            "210                 6:05:37             3:14:38             2:50:59             2:50:54             \n",
            "207                 12:13:19            9:10:35             3:02:44             3:02:39             \n",
            "205                 9:38:07             8:10:24             1:27:43             1:27:38             \n",
            "209                 6:34:13             4:20:44             2:13:29             2:13:24             \n",
            "204                 8:39:25             6:50:00             1:49:25             1:49:19             \n",
            "208                 8:00:58             5:54:09             2:06:49             2:06:44             \n",
            "201                 4:19:09             2:38:41             1:40:28             1:40:28             \n",
            "203                 8:24:28             5:41:16             2:43:11             2:43:06             \n",
            "202                 6:53:36             4:59:01             1:54:35             1:54:35             \n",
            "Loaded model from disk\n",
            "(900, 6, 20)\n",
            "segmenting data with 127756 rows\n",
            "making 249 segments\n",
            "segmenting data with 47044 rows\n",
            "making 71 segments\n",
            "driver_id:          original_size:      stay_size:          driving_size:       cleaned_driving_size: \n",
            "206                 6:44:40             4:46:42             1:57:58             1:57:52             \n",
            "210                 6:05:37             3:14:38             2:50:59             2:50:54             \n",
            "207                 12:13:19            9:10:35             3:02:44             3:02:39             \n",
            "205                 9:38:07             8:10:24             1:27:43             1:27:38             \n",
            "209                 6:34:13             4:20:44             2:13:29             2:13:24             \n",
            "204                 8:39:25             6:50:00             1:49:25             1:49:19             \n",
            "208                 8:00:58             5:54:09             2:06:49             2:06:44             \n",
            "201                 4:19:09             2:38:41             1:40:28             1:40:28             \n",
            "203                 8:24:28             5:41:16             2:43:11             2:43:06             \n",
            "202                 6:53:36             4:59:01             1:54:35             1:54:35             \n",
            "Loaded model from disk\n",
            "(900, 6, 20)\n",
            "segmenting data with 127756 points\n",
            "making 249 segments\n",
            "segmenting data with 47044 points\n",
            "making 71 segments\n",
            "driver_id:          original_size:      stay_size:          driving_size:       cleaned_driving_size: \n",
            "206                 6:44:40             4:46:42             1:57:58             1:57:52             \n",
            "210                 6:05:37             3:14:38             2:50:59             2:50:54             \n",
            "207                 12:13:19            9:10:35             3:02:44             3:02:39             \n",
            "205                 9:38:07             8:10:24             1:27:43             1:27:38             \n",
            "209                 6:34:13             4:20:44             2:13:29             2:13:24             \n",
            "204                 8:39:25             6:50:00             1:49:25             1:49:19             \n",
            "208                 8:00:58             5:54:09             2:06:49             2:06:44             \n",
            "201                 4:19:09             2:38:41             1:40:28             1:40:28             \n",
            "203                 8:24:28             5:41:16             2:43:11             2:43:06             \n",
            "202                 6:53:36             4:59:01             1:54:35             1:54:35             \n",
            "Loaded model from disk\n",
            "(900, 6, 20)\n",
            "segmenting data with 127756 rows\n",
            "making 249 segments\n",
            "segmenting data with 47044 rows\n",
            "making 71 segments\n",
            "driver_id:          original_size:      stay_size:          driving_size:       cleaned_driving_size: \n",
            "206                 6:44:40             4:46:42             1:57:58             1:57:52             \n",
            "210                 6:05:37             3:14:38             2:50:59             2:50:54             \n",
            "207                 12:13:19            9:10:35             3:02:44             3:02:39             \n",
            "205                 9:38:07             8:10:24             1:27:43             1:27:38             \n",
            "209                 6:34:13             4:20:44             2:13:29             2:13:24             \n",
            "204                 8:39:25             6:50:00             1:49:25             1:49:19             \n",
            "208                 8:00:58             5:54:09             2:06:49             2:06:44             \n",
            "201                 4:19:09             2:38:41             1:40:28             1:40:28             \n",
            "203                 8:24:28             5:41:16             2:43:11             2:43:06             \n",
            "202                 6:53:36             4:59:01             1:54:35             1:54:35             \n",
            "Loaded model from disk\n",
            "(900, 6, 20)\n",
            "segmenting data with 127756 rows\n",
            "making 249 segments\n",
            "segmenting data with 47044 rows\n",
            "making 71 segments\n",
            "driver_id:          original_size:      stay_size:          driving_size:       cleaned_driving_size: \n",
            "206                 6:44:40             4:46:42             1:57:58             1:57:52             \n",
            "210                 6:05:37             3:14:38             2:50:59             2:50:54             \n",
            "207                 12:13:19            9:10:35             3:02:44             3:02:39             \n",
            "205                 9:38:07             8:10:24             1:27:43             1:27:38             \n",
            "209                 6:34:13             4:20:44             2:13:29             2:13:24             \n",
            "204                 8:39:25             6:50:00             1:49:25             1:49:19             \n",
            "208                 8:00:58             5:54:09             2:06:49             2:06:44             \n",
            "201                 4:19:09             2:38:41             1:40:28             1:40:28             \n",
            "203                 8:24:28             5:41:16             2:43:11             2:43:06             \n",
            "202                 6:53:36             4:59:01             1:54:35             1:54:35             \n",
            "Loaded model from disk\n",
            "(900, 6, 20)\n",
            "segmenting data with 127756 rows\n",
            "making 249 segments\n",
            "segmenting data with 47044 rows\n",
            "making 71 segments\n",
            "driver_id:          original_size:      stay_size:          driving_size:       cleaned_driving_size: \n",
            "206                 6:44:40             4:46:42             1:57:58             1:57:52             \n",
            "210                 6:05:37             3:14:38             2:50:59             2:50:54             \n",
            "207                 12:13:19            9:10:35             3:02:44             3:02:39             \n",
            "205                 9:38:07             8:10:24             1:27:43             1:27:38             \n",
            "209                 6:34:13             4:20:44             2:13:29             2:13:24             \n",
            "204                 8:39:25             6:50:00             1:49:25             1:49:19             \n",
            "208                 8:00:58             5:54:09             2:06:49             2:06:44             \n",
            "201                 4:19:09             2:38:41             1:40:28             1:40:28             \n",
            "203                 8:24:28             5:41:16             2:43:11             2:43:06             \n",
            "202                 6:53:36             4:59:01             1:54:35             1:54:35             \n",
            "Loaded model from disk\n",
            "(900, 6, 20)\n",
            "segmenting data with 127756 rows\n",
            "making 249 segments\n",
            "segmenting data with 47044 rows\n",
            "making 71 segments\n",
            "driver_id:          original_size:      stay_size:          driving_size:       cleaned_driving_size: \n",
            "206                 6:44:40             4:46:42             1:57:58             1:57:52             \n",
            "210                 6:05:37             3:14:38             2:50:59             2:50:54             \n",
            "207                 12:13:19            9:10:35             3:02:44             3:02:39             \n",
            "205                 9:38:07             8:10:24             1:27:43             1:27:38             \n",
            "209                 6:34:13             4:20:44             2:13:29             2:13:24             \n",
            "204                 8:39:25             6:50:00             1:49:25             1:49:19             \n",
            "208                 8:00:58             5:54:09             2:06:49             2:06:44             \n",
            "201                 4:19:09             2:38:41             1:40:28             1:40:28             \n",
            "203                 8:24:28             5:41:16             2:43:11             2:43:06             \n",
            "202                 6:53:36             4:59:01             1:54:35             1:54:35             \n",
            "Loaded model from disk\n",
            "(900, 6, 20)\n",
            "segmenting data with 127756 rows\n",
            "making 249 segments\n",
            "segmenting data with 47044 rows\n",
            "making 71 segments\n",
            "driver_id:          original_size:      stay_size:          driving_size:       cleaned_driving_size: \n",
            "206                 6:44:40             4:46:42             1:57:58             1:57:52             \n",
            "210                 6:05:37             3:14:38             2:50:59             2:50:54             \n",
            "207                 12:13:19            9:10:35             3:02:44             3:02:39             \n",
            "205                 9:38:07             8:10:24             1:27:43             1:27:38             \n",
            "209                 6:34:13             4:20:44             2:13:29             2:13:24             \n",
            "204                 8:39:25             6:50:00             1:49:25             1:49:19             \n",
            "208                 8:00:58             5:54:09             2:06:49             2:06:44             \n",
            "201                 4:19:09             2:38:41             1:40:28             1:40:28             \n",
            "203                 8:24:28             5:41:16             2:43:11             2:43:06             \n",
            "202                 6:53:36             4:59:01             1:54:35             1:54:35             \n",
            "Loaded model from disk\n",
            "(900, 6, 20)\n",
            "segmenting data with 127756 rows\n",
            "making 249 segments\n",
            "segmenting data with 47044 rows\n",
            "making 71 segments\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(\"method\").mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "ls9vQlhwO0_H",
        "outputId": "8e4c732b-acf8-4f91-9eb8-6d62bd80eeda"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1540cbb1-bd1b-4bdd-961f-17fdc07c731d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>scores</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>method</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>all</th>\n",
              "      <td>0.000376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>histogram</th>\n",
              "      <td>0.000792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spectral</th>\n",
              "      <td>0.000138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>statistical</th>\n",
              "      <td>0.000738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>temporal</th>\n",
              "      <td>0.000502</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1540cbb1-bd1b-4bdd-961f-17fdc07c731d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1540cbb1-bd1b-4bdd-961f-17fdc07c731d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1540cbb1-bd1b-4bdd-961f-17fdc07c731d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "               scores\n",
              "method               \n",
              "all          0.000376\n",
              "histogram    0.000792\n",
              "spectral     0.000138\n",
              "statistical  0.000738\n",
              "temporal     0.000502"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4xiZvRXVmhx"
      },
      "source": [
        "##Mutual Information"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns =['scores', 'method']\n",
        "df = pd.DataFrame(columns = columns)\n",
        "for n_driver in range(10,11):\n",
        "  drivers = random.sample([i for i in range(201,211)], n_driver)\n",
        "  for approach in ['histogram', 'statistical', 'all', 'temporal', 'spectral']:\n",
        "    for data_aug_condition in [True]:\n",
        "        initialization(n_driver)\n",
        "        read_data(drivers)\n",
        "        data_standardization()\n",
        "        data_augmentation(data_aug_condition)\n",
        "        feature_extraction('all')\n",
        "        Xset = SX_train\n",
        "        Yset = y_train\n",
        "\n",
        "        initialization(n_driver)\n",
        "        read_data(drivers)\n",
        "        data_standardization()\n",
        "        data_augmentation(data_aug_condition)\n",
        "        feature_extraction(approach)\n",
        "        feature_selection()\n",
        "        Xsubset = SSX_train\n",
        "        \n",
        "        sam = pd.DataFrame()\n",
        "        sam['score'] = mutual_info_classif(Xset, Yset, n_neighbors=2)\n",
        "        sam.index = Xset.columns.to_list()\n",
        "        score = []\n",
        "        for label in Xsubset.columns.to_list():\n",
        "            score.append([sam.loc[label].score, approach])\n",
        "        df = pd.concat([df, pd.DataFrame(score, columns = columns)])\n",
        "        # counter = 0\n",
        "        # score = 0\n",
        "        # for label in Xsubset.columns.to_list():\n",
        "        #   counter += 1\n",
        "        #   score += sam.loc[label].score\n",
        "        \n",
        "        # print(\"mutual_info_classif\", score/counter, approach, data_aug_condition)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5c5NOVsPA-z",
        "outputId": "41985830-a8b8-49ab-ae5b-432c579b3608"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "driver_id:          original_size:      stay_size:          driving_size:       cleaned_driving_size: \n",
            "209                 6:34:13             4:20:44             2:13:29             2:13:24             \n",
            "204                 8:39:25             6:50:00             1:49:25             1:49:19             \n",
            "202                 6:53:36             4:59:01             1:54:35             1:54:35             \n",
            "205                 9:38:07             8:10:24             1:27:43             1:27:38             \n",
            "206                 6:44:40             4:46:42             1:57:58             1:57:52             \n",
            "210                 6:05:37             3:14:38             2:50:59             2:50:54             \n",
            "207                 12:13:19            9:10:35             3:02:44             3:02:39             \n",
            "201                 4:19:09             2:38:41             1:40:28             1:40:28             \n",
            "203                 8:24:28             5:41:16             2:43:11             2:43:06             \n",
            "208                 8:00:58             5:54:09             2:06:49             2:06:44             \n",
            "Loaded model from disk\n",
            "(900, 6, 20)\n",
            "segmenting data with 127756 rows\n",
            "making 249 segments\n",
            "segmenting data with 47044 rows\n",
            "making 71 segments\n",
            "driver_id:          original_size:      stay_size:          driving_size:       cleaned_driving_size: \n",
            "209                 6:34:13             4:20:44             2:13:29             2:13:24             \n",
            "204                 8:39:25             6:50:00             1:49:25             1:49:19             \n",
            "202                 6:53:36             4:59:01             1:54:35             1:54:35             \n",
            "205                 9:38:07             8:10:24             1:27:43             1:27:38             \n",
            "206                 6:44:40             4:46:42             1:57:58             1:57:52             \n",
            "210                 6:05:37             3:14:38             2:50:59             2:50:54             \n",
            "207                 12:13:19            9:10:35             3:02:44             3:02:39             \n",
            "201                 4:19:09             2:38:41             1:40:28             1:40:28             \n",
            "203                 8:24:28             5:41:16             2:43:11             2:43:06             \n",
            "208                 8:00:58             5:54:09             2:06:49             2:06:44             \n",
            "Loaded model from disk\n",
            "(900, 6, 20)\n",
            "segmenting data with 127756 points\n",
            "making 249 segments\n",
            "segmenting data with 47044 points\n",
            "making 71 segments\n",
            "driver_id:          original_size:      stay_size:          driving_size:       cleaned_driving_size: \n",
            "209                 6:34:13             4:20:44             2:13:29             2:13:24             \n",
            "204                 8:39:25             6:50:00             1:49:25             1:49:19             \n",
            "202                 6:53:36             4:59:01             1:54:35             1:54:35             \n",
            "205                 9:38:07             8:10:24             1:27:43             1:27:38             \n",
            "206                 6:44:40             4:46:42             1:57:58             1:57:52             \n",
            "210                 6:05:37             3:14:38             2:50:59             2:50:54             \n",
            "207                 12:13:19            9:10:35             3:02:44             3:02:39             \n",
            "201                 4:19:09             2:38:41             1:40:28             1:40:28             \n",
            "203                 8:24:28             5:41:16             2:43:11             2:43:06             \n",
            "208                 8:00:58             5:54:09             2:06:49             2:06:44             \n",
            "Loaded model from disk\n",
            "(900, 6, 20)\n",
            "segmenting data with 127756 rows\n",
            "making 249 segments\n",
            "segmenting data with 47044 rows\n",
            "making 71 segments\n",
            "driver_id:          original_size:      stay_size:          driving_size:       cleaned_driving_size: \n",
            "209                 6:34:13             4:20:44             2:13:29             2:13:24             \n",
            "204                 8:39:25             6:50:00             1:49:25             1:49:19             \n",
            "202                 6:53:36             4:59:01             1:54:35             1:54:35             \n",
            "205                 9:38:07             8:10:24             1:27:43             1:27:38             \n",
            "206                 6:44:40             4:46:42             1:57:58             1:57:52             \n",
            "210                 6:05:37             3:14:38             2:50:59             2:50:54             \n",
            "207                 12:13:19            9:10:35             3:02:44             3:02:39             \n",
            "201                 4:19:09             2:38:41             1:40:28             1:40:28             \n",
            "203                 8:24:28             5:41:16             2:43:11             2:43:06             \n",
            "208                 8:00:58             5:54:09             2:06:49             2:06:44             \n",
            "Loaded model from disk\n",
            "(900, 6, 20)\n",
            "segmenting data with 127756 rows\n",
            "making 249 segments\n",
            "segmenting data with 47044 rows\n",
            "making 71 segments\n",
            "driver_id:          original_size:      stay_size:          driving_size:       cleaned_driving_size: \n",
            "209                 6:34:13             4:20:44             2:13:29             2:13:24             \n",
            "204                 8:39:25             6:50:00             1:49:25             1:49:19             \n",
            "202                 6:53:36             4:59:01             1:54:35             1:54:35             \n",
            "205                 9:38:07             8:10:24             1:27:43             1:27:38             \n",
            "206                 6:44:40             4:46:42             1:57:58             1:57:52             \n",
            "210                 6:05:37             3:14:38             2:50:59             2:50:54             \n",
            "207                 12:13:19            9:10:35             3:02:44             3:02:39             \n",
            "201                 4:19:09             2:38:41             1:40:28             1:40:28             \n",
            "203                 8:24:28             5:41:16             2:43:11             2:43:06             \n",
            "208                 8:00:58             5:54:09             2:06:49             2:06:44             \n",
            "Loaded model from disk\n",
            "(900, 6, 20)\n",
            "segmenting data with 127756 rows\n",
            "making 249 segments\n",
            "segmenting data with 47044 rows\n",
            "making 71 segments\n",
            "driver_id:          original_size:      stay_size:          driving_size:       cleaned_driving_size: \n",
            "209                 6:34:13             4:20:44             2:13:29             2:13:24             \n",
            "204                 8:39:25             6:50:00             1:49:25             1:49:19             \n",
            "202                 6:53:36             4:59:01             1:54:35             1:54:35             \n",
            "205                 9:38:07             8:10:24             1:27:43             1:27:38             \n",
            "206                 6:44:40             4:46:42             1:57:58             1:57:52             \n",
            "210                 6:05:37             3:14:38             2:50:59             2:50:54             \n",
            "207                 12:13:19            9:10:35             3:02:44             3:02:39             \n",
            "201                 4:19:09             2:38:41             1:40:28             1:40:28             \n",
            "203                 8:24:28             5:41:16             2:43:11             2:43:06             \n",
            "208                 8:00:58             5:54:09             2:06:49             2:06:44             \n",
            "Loaded model from disk\n",
            "(900, 6, 20)\n",
            "segmenting data with 127756 rows\n",
            "making 249 segments\n",
            "segmenting data with 47044 rows\n",
            "making 71 segments\n",
            "driver_id:          original_size:      stay_size:          driving_size:       cleaned_driving_size: \n",
            "209                 6:34:13             4:20:44             2:13:29             2:13:24             \n",
            "204                 8:39:25             6:50:00             1:49:25             1:49:19             \n",
            "202                 6:53:36             4:59:01             1:54:35             1:54:35             \n",
            "205                 9:38:07             8:10:24             1:27:43             1:27:38             \n",
            "206                 6:44:40             4:46:42             1:57:58             1:57:52             \n",
            "210                 6:05:37             3:14:38             2:50:59             2:50:54             \n",
            "207                 12:13:19            9:10:35             3:02:44             3:02:39             \n",
            "201                 4:19:09             2:38:41             1:40:28             1:40:28             \n",
            "203                 8:24:28             5:41:16             2:43:11             2:43:06             \n",
            "208                 8:00:58             5:54:09             2:06:49             2:06:44             \n",
            "Loaded model from disk\n",
            "(900, 6, 20)\n",
            "segmenting data with 127756 rows\n",
            "making 249 segments\n",
            "segmenting data with 47044 rows\n",
            "making 71 segments\n",
            "driver_id:          original_size:      stay_size:          driving_size:       cleaned_driving_size: \n",
            "209                 6:34:13             4:20:44             2:13:29             2:13:24             \n",
            "204                 8:39:25             6:50:00             1:49:25             1:49:19             \n",
            "202                 6:53:36             4:59:01             1:54:35             1:54:35             \n",
            "205                 9:38:07             8:10:24             1:27:43             1:27:38             \n",
            "206                 6:44:40             4:46:42             1:57:58             1:57:52             \n",
            "210                 6:05:37             3:14:38             2:50:59             2:50:54             \n",
            "207                 12:13:19            9:10:35             3:02:44             3:02:39             \n",
            "201                 4:19:09             2:38:41             1:40:28             1:40:28             \n",
            "203                 8:24:28             5:41:16             2:43:11             2:43:06             \n",
            "208                 8:00:58             5:54:09             2:06:49             2:06:44             \n",
            "Loaded model from disk\n",
            "(900, 6, 20)\n",
            "segmenting data with 127756 rows\n",
            "making 249 segments\n",
            "segmenting data with 47044 rows\n",
            "making 71 segments\n",
            "driver_id:          original_size:      stay_size:          driving_size:       cleaned_driving_size: \n",
            "209                 6:34:13             4:20:44             2:13:29             2:13:24             \n",
            "204                 8:39:25             6:50:00             1:49:25             1:49:19             \n",
            "202                 6:53:36             4:59:01             1:54:35             1:54:35             \n",
            "205                 9:38:07             8:10:24             1:27:43             1:27:38             \n",
            "206                 6:44:40             4:46:42             1:57:58             1:57:52             \n",
            "210                 6:05:37             3:14:38             2:50:59             2:50:54             \n",
            "207                 12:13:19            9:10:35             3:02:44             3:02:39             \n",
            "201                 4:19:09             2:38:41             1:40:28             1:40:28             \n",
            "203                 8:24:28             5:41:16             2:43:11             2:43:06             \n",
            "208                 8:00:58             5:54:09             2:06:49             2:06:44             \n",
            "Loaded model from disk\n",
            "(900, 6, 20)\n",
            "segmenting data with 127756 rows\n",
            "making 249 segments\n",
            "segmenting data with 47044 rows\n",
            "making 71 segments\n",
            "driver_id:          original_size:      stay_size:          driving_size:       cleaned_driving_size: \n",
            "209                 6:34:13             4:20:44             2:13:29             2:13:24             \n",
            "204                 8:39:25             6:50:00             1:49:25             1:49:19             \n",
            "202                 6:53:36             4:59:01             1:54:35             1:54:35             \n",
            "205                 9:38:07             8:10:24             1:27:43             1:27:38             \n",
            "206                 6:44:40             4:46:42             1:57:58             1:57:52             \n",
            "210                 6:05:37             3:14:38             2:50:59             2:50:54             \n",
            "207                 12:13:19            9:10:35             3:02:44             3:02:39             \n",
            "201                 4:19:09             2:38:41             1:40:28             1:40:28             \n",
            "203                 8:24:28             5:41:16             2:43:11             2:43:06             \n",
            "208                 8:00:58             5:54:09             2:06:49             2:06:44             \n",
            "Loaded model from disk\n",
            "(900, 6, 20)\n",
            "segmenting data with 127756 rows\n",
            "making 249 segments\n",
            "segmenting data with 47044 rows\n",
            "making 71 segments\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(\"method\").mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "oNjKULDE-6gb",
        "outputId": "9f31e4de-80f7-4a84-b623-6f4c77da9cc1"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5c4b10e9-d940-49c1-a186-894543ede9da\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>scores</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>method</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>all</th>\n",
              "      <td>0.267080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>histogram</th>\n",
              "      <td>0.344685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spectral</th>\n",
              "      <td>0.219930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>statistical</th>\n",
              "      <td>0.339700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>temporal</th>\n",
              "      <td>0.321033</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c4b10e9-d940-49c1-a186-894543ede9da')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5c4b10e9-d940-49c1-a186-894543ede9da button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5c4b10e9-d940-49c1-a186-894543ede9da');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "               scores\n",
              "method               \n",
              "all          0.267080\n",
              "histogram    0.344685\n",
              "spectral     0.219930\n",
              "statistical  0.339700\n",
              "temporal     0.321033"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    }
  ]
}